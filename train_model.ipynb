{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aIL2RVeNfis1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-42256d4cd2f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from google.colab.patches import cv2_imshow\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset_filtering.data_generation import DataGeneration\n",
    "from dataset_filtering.filter_cats import filtered_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nm4h82NhiWe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dwKyh5yj3u2y",
    "outputId": "dc080f0d-d1c5-4c72-b59a-44a13f31360e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFWtiOW-rsd7"
   },
   "outputs": [],
   "source": [
    "SIZE_X = 416\n",
    "SIZE_Y = 416\n",
    "N_CATS = 16\n",
    "\n",
    "INPUT_SHAPE = (SIZE_X, SIZE_Y, 3)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "TRAIN_IMAGES_PATH = \"/content/images/train/images\"\n",
    "TRAIN_ANNOTATIONS_PATH = \"/content/images/train/annotations.json\"\n",
    "TEST_IMAGES_PATH = \"/content/images/test/images\"\n",
    "TEST_ANNOTATIONS_PATH = \"/content/images/test/annotations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTrPS7sMbbuh"
   },
   "outputs": [],
   "source": [
    "def batch_generator(batchsize, images_path, annotation_path):\n",
    "  i_img = 0\n",
    "  coco = COCO(annotation_path)\n",
    "\n",
    "  categories_ids, categories_names, img_ids = filtered_cats(coco, n=N_CATS)\n",
    "\n",
    "  images = coco.loadImgs(img_ids)\n",
    "  img_paths = [img[\"file_name\"] for img in images]\n",
    "\n",
    "  data_gen = DataGeneration(coco, SIZE_X, SIZE_Y, categories_ids)\n",
    "\n",
    "  while i_img < len(img_paths):\n",
    "    inputs = np.zeros((batchsize, SIZE_X, SIZE_Y, 3))\n",
    "    outputs = np.zeros((batchsize, SIZE_X, SIZE_Y, N_CATS))\n",
    "\n",
    "    for i in range(batchsize):\n",
    "      inputs[i] = data_gen.x_sample(join(images_path, img_paths[i_img]))\n",
    "      outputs[i] = data_gen.y_sample(img_ids[i_img])\n",
    "\n",
    "      i_img += 1\n",
    "\n",
    "    yield normalize(inputs), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fvaIDEFiUPC"
   },
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "  x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  x = Dropout(0.1)(x)\n",
    "\n",
    "  x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JIZHqmEmR31"
   },
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "  x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "  x = Concatenate()([x, skip_features])\n",
    "  x = conv_block(x, num_filters)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-HvPHiwmc5Q"
   },
   "outputs": [],
   "source": [
    "def build_vgg19_unet(input_shape, n_classes=1):\n",
    "  \"\"\" Input \"\"\"\n",
    "  inputs = Input(input_shape)\n",
    "\n",
    "  \"\"\" Pre-trained VGG19 Model \"\"\"\n",
    "  vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "  for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  \"\"\" Encoder \"\"\"\n",
    "  s1 = vgg19.get_layer(\"block1_conv2\").output         ## (512 x 512)\n",
    "  s2 = vgg19.get_layer(\"block2_conv2\").output         ## (256 x 256)\n",
    "  s3 = vgg19.get_layer(\"block3_conv4\").output         ## (128 x 128)\n",
    "  s4 = vgg19.get_layer(\"block4_conv4\").output         ## (64 x 64)\n",
    "\n",
    "  \"\"\" Bridge \"\"\"\n",
    "  b1 = vgg19.get_layer(\"block5_conv4\").output         ## (32 x 32)\n",
    "\n",
    "  \"\"\" Decoder \"\"\"\n",
    "  d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
    "  d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
    "  d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
    "  d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
    "\n",
    "  \"\"\" Output \"\"\"\n",
    "  outputs = Conv2D(n_classes, (1,1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "  model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-syBGFvTrbvL"
   },
   "outputs": [],
   "source": [
    "model = build_vgg19_unet(INPUT_SHAPE, N_CATS)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[MeanIoU(N_CATS)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsleFG9f02re"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "             ModelCheckpoint(\"/content/logs/model_checkpoints/food_segmentation.h5\", verbose=1, save_best_only=True),\n",
    "             EarlyStopping(patience=3, monitor=\"val_loss\"),\n",
    "             TensorBoard(log_dir=\"/content/logs/tensorboard_logs\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V24-UbVFt2Ob"
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "  history = model.fit_generator(\n",
    "                      batch_generator(BATCH_SIZE, TRAIN_IMAGES_PATH, TRAIN_ANNOTATIONS_PATH),\n",
    "                      verbose=1,\n",
    "                      epochs=50,\n",
    "                      validation_data=batch_generator(BATCH_SIZE, TEST_IMAGES_PATH, TEST_ANNOTATIONS_PATH),\n",
    "                      #class_weight=class_weights,\n",
    "                      shuffle=True,\n",
    "                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0h6DDx-ziwq"
   },
   "outputs": [],
   "source": [
    "model.save('food_recognition_50_epochs_test.hdf5') #Saving a model with 50 epochs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
